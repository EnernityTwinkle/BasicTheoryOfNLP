## 交叉熵损失函数（适合衡量两个概率分布的差异）

$H(y^{(i)}, \hat{y}^{(i)}) = -\sum_{j=1}^{n}y_j^{(i)}log\hat{y}_j^{(i)}$

其中$y^{(i)}$是真实的概率分布，$\hat{y}^{(i)}$是模型预测的概率分布。

## Hinge损失函数(SVM使用的损失函数)

Hinge损失函数标准形式如下：

$L(y,f(x))=max(0,1-yf(x))$,

其中$y$是真实label(-1或1)，$f(x)$是预测值，在-1到1之间。

特点：

（1）hinge损失函数表示如果分类正确，损失为0，否则损失为$1-yf(x)$

（2）健壮性相对较高，对异常点、噪声不敏感，但没有太好的概率解释。

## 平方损失函数

平方损失函数标准形式如下：

$L(Y|f(X))=\sum_{N}(Y-f(X))^2$

特点：经常应用与回归问题中。

## 0-1损失函数

0-1损失是指预测值和目标值不相等为1，否则为0：
$$L(Y,f(X))= \{\begin{matrix}
1,Y\neq f(X)\\ 
0,Y=f(X)
\end{matrix}.$$

特点：

（1）0-1损失函数直接对应分类错误的个数

（2）感知机使用的就是这种损失函数。但相等这个条件过于严格，因此可以放宽条件，即满足$|Y-f(x)|<T$时认为相等。

# 相关知识问答

### 交叉熵函数与最大似然函数的联系和区别[<sup>1</sup>](#refer-anchor-1)？

\>>区别：交叉熵函数用来描述模型预测值和真实值的差距大小，越大代表越不相近；似然函数的本质是衡量在某个参数下，整体的估计和真实情况一样的概率，越大表示越相近。

联系：交叉熵函数可以由最大似然函数在伯努利分布的条件下推导出来，即最小化交叉熵函数的本质就是对数似然函数的最大化。


# 参考文献

<div id="refer-anchor-1"></div>
- [1] [常用损失函数-知乎](https://zhuanlan.zhihu.com/p/58883095)
